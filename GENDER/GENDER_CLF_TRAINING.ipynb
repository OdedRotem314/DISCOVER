{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dependencies\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import  Input, Dense, Flatten, Dropout, Conv2D, Activation, Add, BatchNormalization, AveragePooling2D, Concatenate\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import activations\n",
    "from keras.losses import BinaryCrossentropy\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from keras.models import Model, load_model\n",
    "from keras.losses import binary_crossentropy, mean_squared_error\n",
    "from keras.initializers import glorot_uniform\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder , StandardScaler , PolynomialFeatures , MinMaxScaler\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializations\n",
    "\n",
    "img_size, num_channels = 64,1\n",
    "equalize_classes = 0 # flag for oversampling minority class if needed\n",
    "aug_data_flag = 1    # flag for using augmentations\n",
    "clf_model = 'vgg'    # which backbone to use for the classifier inception, resnet, vgg, densenet, encoder, simple_cnn,  ccf_model , load_custom_model\n",
    "last_layers_are_needed = 1 # adding MLP after convolutional layers to customize the classifier for binary output\n",
    "retrain_model = 1 # 0-imagenet weights , 1- initialize from imagenet, None for random weights not \"imagenet \n",
    "seed_val = 3 \n",
    "margin=15 # crop the edges of the images\n",
    "data_path = '/home/odedrot' # user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions used for displaying outpus\n",
    "\n",
    "def plot_imgs_withLabels_3D(imgs, labels, n_examples, fig_size):\n",
    "    n = int(np.sqrt(n_examples))\n",
    "    k=0\n",
    "    fig, ax = plt.subplots(n, n, figsize=(fig_size,fig_size))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            ax[i, j] .imshow(imgs[k].reshape(img_size, img_size, 3), cmap='gray')\n",
    "            ax[i, j].axis('off')\n",
    "            ax[i, j].set_title(labels[k])\n",
    "            k = k + 1\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_imgs_withLabelsandpred_3D(imgs, labels, n_examples, fig_size):\n",
    "    n = int(np.sqrt(n_examples))\n",
    "    k=0\n",
    "    fig, ax = plt.subplots(n, n, figsize=(fig_size,fig_size))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            ax[i, j] .imshow(imgs[k].reshape(img_size, img_size, 3), cmap='gray')\n",
    "            ax[i, j].axis('off')\n",
    "            ax[i, j].set_title(labels[k])\n",
    "            k = k + 1\n",
    "    fig.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "def plot_imgs_withLabels_1D(imgs, labels, n_examples, fig_size):\n",
    "    n = int(np.sqrt(n_examples))\n",
    "    k=0\n",
    "    fig, ax = plt.subplots(n, n, figsize=(fig_size,fig_size))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            ax[i, j] .imshow(imgs[k].reshape(img_size, img_size, 1), cmap='gray')\n",
    "            ax[i, j].axis('off')\n",
    "            ax[i, j].set_title(labels[k], fontsize=30)\n",
    "            k = k + 1\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# plot_imgs_withLabels(images, images_id, 144, 15)\n",
    "\n",
    "def sample_images(imgs, r,c):\n",
    "    fig, axs = plt.subplots(r, c, figsize=(20,2*r))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()\n",
    "##############################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load images \n",
    "\n",
    "def load_images(directory):\n",
    "    imagePaths = list(paths.list_images(directory))\n",
    "    data = []\n",
    "    images_name = []\n",
    "    labels = []\n",
    "    for imagePath in imagePaths:\n",
    "        # name\n",
    "        img_name = imagePath.split(\"/\")[-1]\n",
    "        images_name.append(img_name)\n",
    "        # labels\n",
    "        labels.append(0)\n",
    "        # image\n",
    "        image = cv2.imread(imagePath) # load the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # swap color channels \n",
    "        image = image[margin:img_size-margin , margin:img_size-margin] \n",
    "        image = cv2.resize(image, (img_size,img_size) , interpolation = cv2.INTER_AREA)\n",
    "        data.append(image)\n",
    "        \n",
    "    data_arr = np.array(data)\n",
    "    labels_arr = np.array(labels)\n",
    "    print(data_arr.shape, np.min(data_arr), np.max(data_arr), data_arr.dtype)\n",
    "    return data_arr, images_name, labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load train/test datasets\n",
    "\n",
    "print('female train')\n",
    "images_1, names_1, labels_1                = load_images(data_path + '/DISCOVERY-master/GENDER/IMAGES/TRAIN_1') \n",
    "print('male train')\n",
    "images_0, names_0, labels_0                = load_images(data_path + '/DISCOVERY-master/GENDER/IMAGES/TRAIN_0') \n",
    "\n",
    "print('female test')\n",
    "images_1_test, names_1_test, labels_1_test = load_images(data_path + '/DISCOVERY-master/GENDER/IMAGES/TEST_1') \n",
    "print('male test')\n",
    "images_0_test, names_0_test, labels_0_test  = load_images(data_path + '/DISCOVERY-master/GENDER/IMAGES/TEST_0') \n",
    "\n",
    "print('Done loading images')\n",
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## verify no leakage \n",
    "print( set(names_1) == set(names_1_test) )\n",
    "print( set(names_0) == set(names_0_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equalize data from both classes for training and merge both classes to one training dataset\n",
    "\n",
    "train_images_0 = images_0 \n",
    "train_images_1 = images_1\n",
    "\n",
    "### upsample class 0\n",
    "# n_upsample_0 = 400\n",
    "# rand_ind=np.random.randint(0,len(train_images_0),n_upsample_0)\n",
    "# train_images_0 =  np.concatenate(( train_images_0, train_images_0[rand_ind]))\n",
    "### upsample class 1\n",
    "# n_upsample_1 = 400\n",
    "# rand_ind=np.random.randint(0,len(train_images_1),n_upsample_1)\n",
    "# train_images_1 =  np.concatenate(( train_images_1, train_images_1[rand_ind]))\n",
    "\n",
    "\n",
    "if equalize_classes == 1:  \n",
    "    def euql_cls(imgs_maj, imgs_min):\n",
    "        delta = len(imgs_maj) - len(imgs_min)\n",
    "        np.random.seed(seed_val)\n",
    "        rand_ind=np.random.randint(0,len(imgs_min),delta)\n",
    "        imgs_min =  np.concatenate(( imgs_min, imgs_min[rand_ind]))\n",
    "        return imgs_maj, imgs_min\n",
    "    \n",
    "    if len(train_images_0) > len(train_images_1):\n",
    "        train_images_0, train_images_1 = euql_cls(train_images_0, train_images_1)\n",
    "             \n",
    "    if len(train_images_1) > len(train_images_0):\n",
    "        train_images_1, train_images_0 = euql_cls(train_images_1, train_images_0)\n",
    "\n",
    "p_label = 1 # 1\n",
    "n_label = 0 # 0\n",
    "\n",
    "train_images = np.concatenate(( train_images_0 , train_images_1))\n",
    "train_labels = np.concatenate(( n_label*np.ones(len(train_images_0)) , p_label*np.ones(len(train_images_1)) ))\n",
    "\n",
    "## test \n",
    "test_images_0 = images_0_test \n",
    "test_images_1 = images_1_test \n",
    "test_images = np.concatenate(( test_images_0, test_images_1))\n",
    "test_labels = np.concatenate(( n_label*np.ones(len(test_images_0)) , p_label*np.ones(len(test_images_1)) ))\n",
    "\n",
    "test_names_0 = names_0_test \n",
    "test_names_1 = names_1_test   \n",
    "test_names = np.concatenate(( test_names_0,     test_names_1))\n",
    "\n",
    "# shuffle\n",
    "(X_train, y_train) = shuffle(train_images, train_labels)\n",
    "(X_test, y_test, X_test_names) = shuffle(test_images, test_labels, test_names)\n",
    "\n",
    "print('')\n",
    "print('train_images_0', train_images_0.shape)\n",
    "print('train_images_1', train_images_1.shape)\n",
    "print('')\n",
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGMENTATIONS\n",
    "\n",
    "@tf.function\n",
    "def brightness(x):\n",
    "    x = tf.image.random_brightness(x, 0.15)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "@tf.function\n",
    "def contrast(x):\n",
    "    x = tf.image.random_contrast(x, 0.85, 1.15)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "@tf.function\n",
    "def rotate(x):\n",
    "    orient = np.random.choice([1,2,3], 1)[0] # 90,180,270\n",
    "    x = tf.image.rot90(x, k=orient)\n",
    "    # x = tf.contrib.image.rotate(y, angles=2.356194490192345, interpolation='NEAREST')\n",
    "    return x\n",
    "@tf.function\n",
    "def flip_ver(x):\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    return x\n",
    "@tf.function\n",
    "def flip_hor(x):\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x\n",
    "@tf.function\n",
    "def add_noise(x):\n",
    "    x_noise = tf.random.normal(shape=(img_size, img_size, 1), mean=0.0, stddev=0.03, dtype=tf.float32)\n",
    "    x = tf.add(x, x_noise) \n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "@tf.function\n",
    "def resize_crop(x):\n",
    "    rand_size = tf.random.uniform(shape=[],  minval=int(0.75 * img_size),  maxval=1 * img_size, dtype=tf.int32,)\n",
    "    crop = tf.image.random_crop(x, (rand_size, rand_size, x.shape[-1]))\n",
    "    x = tf.image.resize(crop, (img_size, img_size))\n",
    "    return x\n",
    "@tf.function\n",
    "def blur(x):\n",
    "    # s = np.random.random()\n",
    "    # x = tfa.image.gaussian_filter2d(image=x, sigma=s)     \n",
    "    x = tfa.image.gaussian_filter2d(x, filter_shape=(3,3), sigma=0.3)\n",
    "    return x\n",
    "\n",
    "def augment_img(img):\n",
    "    img_aug = np.copy(img)\n",
    "    ### flip hor\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = flip_hor(img_aug)\n",
    "    ### flip ver\n",
    "    # rand_val = np.random.uniform(0,1)\n",
    "    # if rand_val > 0.5:\n",
    "    #     img_aug = flip_ver(img_aug)\n",
    "    ### rotate\n",
    "    # rand_val = np.random.uniform(0,1)\n",
    "    # if rand_val > 0.5:\n",
    "    #     img_aug = rotate(img_aug)\n",
    "    ### resize crop\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = resize_crop(img_aug)\n",
    "        \n",
    "    ### blur\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = blur(img_aug)\n",
    "    ### brightness\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = brightness(img_aug)\n",
    "    ### contrast\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = contrast(img_aug)\n",
    "    ### noise\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = add_noise(img_aug)\n",
    "    return img_aug\n",
    "\n",
    "\n",
    "def augment_imgs(imgs):\n",
    "    imgs_aug = []\n",
    "    for i in range(len(imgs)):\n",
    "        img_aug = augment_img(imgs[i])\n",
    "        imgs_aug.append( img_aug )\n",
    "    imgs_aug = np.array(imgs_aug)\n",
    "    return imgs_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the model.\n",
    "## define the backbone and training from scracth or from pretrained weights\n",
    "\n",
    "# if clf_model == 'load_custom_model': \n",
    "#     CNN_saved_name = 'saved_model_name.h5' # new\n",
    "#     CNN_clf_model_path = '/saved_dir/' + CNN_saved_name\n",
    "#     model = load_model(CNN_clf_model_path , compile=True)\n",
    "if clf_model == 'resnet': \n",
    "    model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size,3)) # Xception ResNet50\n",
    "if clf_model == 'vgg': # \"imagenet\" or None\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size,3)) # None , \"imagenet\"\n",
    "if clf_model == 'densenet': \n",
    "    model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size,3)) # Xception ResNet50    \n",
    "if clf_model == 'simple_cnn':\n",
    "    input_D = Input(shape=(img_size, img_size, 3))\n",
    "    X = Conv2D(filters=128, kernel_size=5, strides=2, activation='relu', padding='same')(input_D) #### HP #####\n",
    "    X = Conv2D(filters=128, kernel_size=7, strides=1, activation='relu', padding='same')(X)\n",
    "    X = Dropout(0.15)(X)\n",
    "    X = Conv2D(filters=256, kernel_size=5, strides=2, activation='relu', padding='same')(X)\n",
    "    X = Conv2D(filters=256, kernel_size=7, strides=1, activation='relu', padding='same')(X)\n",
    "    X = Dropout(0.15)(X)\n",
    "    X = Conv2D(filters=512, kernel_size=5, strides=2, activation='relu', padding='same')(X)\n",
    "    X = Conv2D(filters=512, kernel_size=7, strides=1, activation='relu', padding='same')(X)\n",
    "    X = Dropout(0.15)(X)\n",
    "#     X = BatchNormalization()(X)\n",
    "#     X = Dropout(0.1)(X)\n",
    "    model = Model(input_D, X)\n",
    "#####################################################################################################\n",
    "if retrain_model==0:\n",
    "    for layer in model.layers: # retrain all layers\n",
    "        layer.trainable = False \n",
    "if retrain_model==1:\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True \n",
    "######################################################################################################\n",
    "# flatten and add dense layers\n",
    "if last_layers_are_needed == 1:\n",
    "    X = model.output\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(16, activation='relu')(X)  #### HP #####\n",
    "    X = Dropout(0.5)(X)\n",
    "    output_linear = Dense(1)(X)\n",
    "    output_sigmoid = activations.sigmoid(output_linear)\n",
    "    final_model = Model(inputs=model.inputs, outputs=output_sigmoid)\n",
    "if last_layers_are_needed == 0:\n",
    "    final_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameters and optimizer\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 300\n",
    "LEARNING_RATE = 0.00000001\n",
    "optimizer=Adam(LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lossess and metrics\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.3)\n",
    "\n",
    "def bce_loss(y_real, y_pred):\n",
    "    bce_losses = -1* ( y_real*tf.math.log(y_pred) + (1-y_real)*(tf.math.log(1 - y_pred)) ) # positive value\n",
    "    # bce_losses = bce_losses[bce_losses>0.5]\n",
    "    return tf.math.reduce_mean( bce_losses )\n",
    "\n",
    "def calc_metrices(y_real, y_pred):\n",
    "        clf_loss = bce(y_real, y_pred).numpy()\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_real , y_pred)\n",
    "        auc_score = np.round(metrics.roc_auc_score(y_real , y_pred),2)\n",
    "        gmeans = np.sqrt(tpr * (1-fpr))\n",
    "        ix = np.argmax(gmeans) # locate the index of the largest g-mean\n",
    "        gmax = np.round(gmeans[ix],2)\n",
    "        th = np.round(thresholds[ix],2)\n",
    "        tpr = np.round(tpr[ix],2)\n",
    "        tnr = np.round(1-fpr[ix],2)\n",
    "        \n",
    "        y_pred_TH = np.copy(y_pred)\n",
    "        y_pred_TH[y_pred>th] = 1\n",
    "        y_pred_TH[y_pred<th] = 0\n",
    "        acc = metrics.accuracy_score(y_real, y_pred_TH)\n",
    "        f1 = f1_score(y_real, y_pred_TH)\n",
    "        return clf_loss, tnr, tpr, gmax, th, auc_score, acc, f1\n",
    "    \n",
    "def plot_hist(y_real, y_pred):\n",
    "        _ = plt.hist(y_pred[y_real==0] , 100, alpha = 0.5, color= 'r')\n",
    "        _ = plt.hist(y_pred[y_real==1] , 100, alpha = 0.5, color= 'b')\n",
    "        # plt.title('Quality scores based on real images', fontsize=20)\n",
    "        handles = [Rectangle((0,0),1,1,color=c,ec=\"k\") for c in [\"red\", \"blue\"] ]\n",
    "        labels= [\"low\", \"high\"]\n",
    "        plt.legend(handles, labels)\n",
    "        plt.xlabel(\"classifier scores\", fontsize=15)\n",
    "        plt.ylabel(\"# of samples\", fontsize=15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training model and save\n",
    "\n",
    "test_imgs = X_test.astype(\"float32\") / 255\n",
    "test_imgs = np.expand_dims(test_imgs,-1)\n",
    "test_imgs = test_imgs.repeat(3, -1)\n",
    "\n",
    "idx = np.random.randint(0, X_train.shape[0], 2000)\n",
    "train_imgs = np.copy(X_train[idx]).astype(\"float32\") / 255\n",
    "train_imgs = np.expand_dims(train_imgs,-1)\n",
    "train_imgs = train_imgs.repeat(3, -1)\n",
    "train_y = y_train[idx]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch)\n",
    "    iteration = 0\n",
    "    for n_batch in range(len(X_train) // batch_size): \n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        image_batch = np.copy(X_train[idx]).astype(\"float32\") / 255\n",
    "        image_batch = np.expand_dims(image_batch,-1)\n",
    "        y_batch = np.copy(y_train[idx])\n",
    "        y_batch = tf.convert_to_tensor(y_batch.astype('float32'))\n",
    "        if aug_data_flag==1:\n",
    "            image_batch = augment_imgs(image_batch) # \n",
    "        image_batch = image_batch.repeat(3, -1)\n",
    "        with tf.GradientTape() as tape:\n",
    "            clf_pred = final_model(image_batch, training=True)\n",
    "            clf_loss = bce(y_batch, clf_pred)\n",
    "        trainable_variables = final_model.trainable_variables\n",
    "        clf_gradients = tape.gradient(clf_loss, trainable_variables)\n",
    "        optimizer.apply_gradients(zip(clf_gradients, trainable_variables))\n",
    "            \n",
    "    # end of epoch - test \n",
    "    \n",
    "    if epoch % 3 == 0:\n",
    "    \n",
    "        print('')\n",
    "        train_clf_pred = final_model.predict(train_imgs)[:,0]    \n",
    "        test_clf_pred = final_model.predict(test_imgs)[:,0]\n",
    "\n",
    "        train_clf_loss, train_tnr, train_tpr, train_gmax, train_th, train_auc, train_acc, train_f1 = calc_metrices(train_y, train_clf_pred)\n",
    "        test_clf_loss, test_tnr, test_tpr, test_gmax, test_th, test_auc, test_acc, test_f1 = calc_metrices(y_test, test_clf_pred)\n",
    "\n",
    "        print('train', '                 ','test')\n",
    "        print('loss', train_clf_loss, '    ', test_clf_loss)\n",
    "        print('acc', train_acc, '    ', test_acc)\n",
    "        print('gmax', train_gmax, '    ', test_gmax)\n",
    "        print('th', train_th, '    ', test_th)\n",
    "        print('tnr', train_tnr, '    ', test_tnr)\n",
    "        print('tpr', train_tpr, '    ', test_tpr)\n",
    "        print('auc', train_auc, '    ', test_auc)\n",
    "        print('f1', train_f1, '    ', test_f1)\n",
    "        print('')\n",
    "    \n",
    "    \n",
    "        plot_hist(train_y, train_clf_pred)\n",
    "        plot_hist(y_test, test_clf_pred)\n",
    "    \n",
    "    final_model.save(data_path + 'DISCOVERY/GENDER/GENDER_SAVED_MODELS/classifier.h5, include_optimizer=True)  \n",
    "                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odedenv2",
   "language": "python",
   "name": "odedenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
