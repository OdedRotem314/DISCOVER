{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras.layers import Lambda, Input, GaussianNoise,concatenate, Dense, Dropout, Conv2D, Add, UpSampling2D, Dot, Conv2DTranspose, Activation, Reshape, InputSpec, LeakyReLU, Flatten, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from time import time\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine import *\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.utils.generic_utils import func_dump\n",
    "from keras.utils.generic_utils import func_load\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.utils.generic_utils import has_arg\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers import Dense, Conv1D, Conv2D, Conv3D, Conv2DTranspose, Embedding\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from keras.models import load_model\n",
    "import tensorflow_probability as tfp\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from tensorflow_addons.layers import SpectralNormalization\n",
    "from keras.activations import swish\n",
    "from keras.initializers import glorot_uniform, glorot_normal, GlorotUniform\n",
    "import pandas as pd \n",
    "from keras.constraints import max_norm, UnitNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.10\n",
      "2.6.2\n",
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperperemeter\n",
    "\n",
    "do_augmentations = 0\n",
    "BATCHSIZE=4 # 64\n",
    "LEARNING_RATE = 0.0002 # initial 0.0002\n",
    "TRAINING_RATIO = 1\n",
    "BETA_1 = 0.0\n",
    "BETA_2 = 0.9\n",
    "EPOCHS = 500\n",
    "BN_MIMENTUM = 0.1\n",
    "BN_EPSILON  = 0.00002 \n",
    "latent_dim = 350\n",
    "img_size = 64\n",
    "channels = 1\n",
    "img_shape = (img_size, img_size, channels)\n",
    "nmax = 200\n",
    "ker_init = GlorotUniform(seed=None)\n",
    "noise_var = 1\n",
    "load_model_true = 1\n",
    "do_augmentations = 0\n",
    "upload_saved_model = 0\n",
    "data_path = '/home/odedrot' # user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"=\"*40, \"GPU Details\", \"=\"*40)\n",
    "\n",
    "gpus = GPUtil.getGPUs()\n",
    "list_gpus = []\n",
    "\n",
    "for gpu in gpus:\n",
    "    # get the GPU id\n",
    "    gpu_id = gpu.id\n",
    "    # name of GPU\n",
    "    gpu_name = gpu.name\n",
    "    # get % percentage of GPU usage of that GPU\n",
    "    gpu_load = f\"{gpu.load*100}%\"\n",
    "    # get free memory in MB format\n",
    "    gpu_free_memory = f\"{gpu.memoryFree}MB\"\n",
    "    # get used memory\n",
    "    gpu_used_memory = f\"{gpu.memoryUsed}MB\"\n",
    "    # get total memory\n",
    "    gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
    "    # get GPU temperature in Celsius\n",
    "    gpu_temperature = f\"{gpu.temperature} Â°C\"\n",
    "\n",
    "    list_gpus.append((\n",
    "        gpu_id, gpu_name, gpu_load, gpu_free_memory, gpu_used_memory,\n",
    "        gpu_total_memory, gpu_temperature\n",
    "    ))\n",
    "\n",
    "print(tabulate(list_gpus, headers=(\"id\", \"name\", \"load\", \"free mem\", \"used mem\", \"total mem\",\n",
    "                                   \"temperature\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "margin = 15\n",
    "def load_images(directory):\n",
    "    imagePaths = list(paths.list_images(directory))\n",
    "    data = []\n",
    "    images_name = []\n",
    "    i = 1\n",
    "    for imagePath in imagePaths:\n",
    "        # images_name.append(imagePath.split(\"/\")[5])\n",
    "        image = cv2.imread(imagePath) # load the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # swap color channels\n",
    "        image = image[margin:img_size-margin , margin:img_size-margin] \n",
    "        image = cv2.resize(image, (img_size,img_size) , interpolation = cv2.INTER_AREA)\n",
    "        data.append(image)\n",
    "        i = i+1\n",
    "        if i>nmax:\n",
    "            break\n",
    "    req_images = np.array(data)\n",
    "    req_images =  np.array(req_images).astype(\"float32\")\n",
    "    req_images = np.expand_dims(req_images, axis=-1)\n",
    "    return req_images# , images_name\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# train\n",
    "images0 = load_images(data_path + '/DISCOVERY-master/GENDER/IMAGES/TRAIN_0') \n",
    "images1 = load_images(data_path + '/DISCOVERY-master/GENDER/IMAGES/TRAIN_1') \n",
    "X_train = np.concatenate((images0, images1))\n",
    "\n",
    "################################################################################################\n",
    "# test\n",
    "images0 = load_images(data_path + '/DISCOVERY-master/GENDER/IMAGES/TEST_0') \n",
    "images1 = load_images(data_path + '/DISCOVERY-master/GENDER/IMAGES/TEST_1') \n",
    "\n",
    "X_test = np.concatenate((images0, images1))\n",
    "\n",
    "\n",
    "print('X_train' , X_train.shape)\n",
    "print('X_test' , X_test.shape)\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def brightness(x):\n",
    "    x = tf.image.random_brightness(x, 0.15)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "@tf.function\n",
    "def contrast(x):\n",
    "    x = tf.image.random_contrast(x, 0.85, 1.15)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "@tf.function\n",
    "def rotate(x):\n",
    "    orient = np.random.choice([1,2,3], 1)[0] # 90,180,270\n",
    "    x = tf.image.rot90(x, k=orient)\n",
    "    # x = tf.contrib.image.rotate(y, angles=2.356194490192345, interpolation='NEAREST')\n",
    "    return x\n",
    "@tf.function\n",
    "def flip_ver(x):\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    return x\n",
    "@tf.function\n",
    "def flip_hor(x):\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x\n",
    "@tf.function\n",
    "def add_noise(x):\n",
    "    x_noise = tf.random.normal(shape=(img_size, img_size, 1), mean=0.0, stddev=0.03, dtype=tf.float32)\n",
    "    x = tf.add(x, x_noise) \n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "@tf.function\n",
    "def resize_crop(x):\n",
    "    rand_size = tf.random.uniform(shape=[],  minval=int(0.75 * img_size),  maxval=1 * img_size, dtype=tf.int32,)\n",
    "    crop = tf.image.random_crop(x, (rand_size, rand_size, x.shape[-1]))\n",
    "    x = tf.image.resize(crop, (img_size, img_size))\n",
    "    return x\n",
    "@tf.function\n",
    "def blur(x):\n",
    "    # s = np.random.random()\n",
    "    # x = tfa.image.gaussian_filter2d(image=x, sigma=s)     \n",
    "    x = tfa.image.gaussian_filter2d(x, filter_shape=(3,3), sigma=0.3)\n",
    "    return x\n",
    "\n",
    "def augment_img(img):\n",
    "    img_aug = np.copy(img)\n",
    "    ### flip hor\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = flip_hor(img_aug)\n",
    "    ### flip ver\n",
    "    # rand_val = np.random.uniform(0,1)\n",
    "    # if rand_val > 0.5:\n",
    "    #     img_aug = flip_ver(img_aug)\n",
    "    ### rotate\n",
    "    # rand_val = np.random.uniform(0,1)\n",
    "    # if rand_val > 0.5:\n",
    "    #     img_aug = rotate(img_aug)\n",
    "    ### resize crop\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = resize_crop(img_aug)\n",
    "        \n",
    "    ### blur\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = blur(img_aug)\n",
    "    ### brightness\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = brightness(img_aug)\n",
    "    ### contrast\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = contrast(img_aug)\n",
    "    ### noise\n",
    "    rand_val = np.random.uniform(0,1)\n",
    "    if rand_val > 0.5:\n",
    "        img_aug = add_noise(img_aug)\n",
    "    return img_aug\n",
    "\n",
    "\n",
    "def augment_imgs(imgs):\n",
    "    imgs_aug = []\n",
    "    for i in range(len(imgs)):\n",
    "        img_aug = augment_img(imgs[i])\n",
    "        imgs_aug.append( img_aug )\n",
    "    imgs_aug = np.array(imgs_aug)\n",
    "    return imgs_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(imgs):\n",
    "    r, c = 2, 10\n",
    "    fig, axs = plt.subplots(r, c, figsize=(20,4))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseSN(Dense):\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
    "                                 initializer=initializers.RandomNormal(0, 1),\n",
    "                                 name='sn',\n",
    "                                 trainable=False)\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        def _l2normalize(v, eps=1e-12):\n",
    "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
    "        def power_iteration(W, u):\n",
    "            _u = u\n",
    "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
    "            _u = _l2normalize(K.dot(_v, W))\n",
    "            return _u, _v\n",
    "        W_shape = self.kernel.shape.as_list()\n",
    "        #Flatten the Tensor\n",
    "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
    "        _u, _v = power_iteration(W_reshaped, self.u)\n",
    "        #Calculate Sigma\n",
    "        sigma=K.dot(_v, W_reshaped)\n",
    "        sigma=K.dot(sigma, K.transpose(_u))\n",
    "        #normalize it\n",
    "        W_bar = W_reshaped / sigma\n",
    "        #reshape weight tensor\n",
    "        if training in {0, False}:\n",
    "            W_bar = K.reshape(W_bar, W_shape)\n",
    "        else:\n",
    "            with tf.control_dependencies([self.u.assign(_u)]):\n",
    "                 W_bar = K.reshape(W_bar, W_shape)  \n",
    "        output = K.dot(inputs, W_bar)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "    \n",
    "\n",
    "class ConvSN2D(Conv2D):\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
    "                         initializer=initializers.RandomNormal(0, 1),\n",
    "                         name='sn',\n",
    "                         trainable=False)\n",
    "        \n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "    def call(self, inputs, training=None):\n",
    "        def _l2normalize(v, eps=1e-12):\n",
    "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
    "        def power_iteration(W, u):\n",
    "            #Accroding the paper, we only need to do power iteration one time.\n",
    "            _u = u\n",
    "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
    "            _u = _l2normalize(K.dot(_v, W))\n",
    "            return _u, _v\n",
    "        #Spectral Normalization\n",
    "        W_shape = self.kernel.shape.as_list()\n",
    "        #Flatten the Tensor\n",
    "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
    "        _u, _v = power_iteration(W_reshaped, self.u)\n",
    "        #Calculate Sigma\n",
    "        sigma=K.dot(_v, W_reshaped)\n",
    "        sigma=K.dot(sigma, K.transpose(_u))\n",
    "        #normalize it\n",
    "        W_bar = W_reshaped / sigma\n",
    "        #reshape weight tensor\n",
    "        if training in {0, False}:\n",
    "            W_bar = K.reshape(W_bar, W_shape)\n",
    "        else:\n",
    "            with tf.control_dependencies([self.u.assign(_u)]):\n",
    "                W_bar = K.reshape(W_bar, W_shape)\n",
    "                \n",
    "        outputs = K.conv2d(\n",
    "                inputs,\n",
    "                W_bar,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs    \n",
    "\n",
    "    \n",
    "class ConvSN2DTranspose(Conv2DTranspose):\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError('Inputs should have rank ' +\n",
    "                             str(4) +\n",
    "                             '; Received input shape:', str(input_shape))\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (self.filters, input_dim)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
    "                         initializer=initializers.RandomNormal(0, 1),\n",
    "                         name='sn',\n",
    "                         trainable=False)\n",
    "        \n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n",
    "        self.built = True  \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        if self.data_format == 'channels_first':\n",
    "            h_axis, w_axis = 2, 3\n",
    "        else:\n",
    "            h_axis, w_axis = 1, 2\n",
    "\n",
    "        height, width = input_shape[h_axis], input_shape[w_axis]\n",
    "        kernel_h, kernel_w = self.kernel_size\n",
    "        stride_h, stride_w = self.strides\n",
    "        if self.output_padding is None:\n",
    "            out_pad_h = out_pad_w = None\n",
    "        else:\n",
    "            out_pad_h, out_pad_w = self.output_padding\n",
    "\n",
    "        # Infer the dynamic output shape:\n",
    "        out_height = conv_utils.deconv_length(height,\n",
    "                                              stride_h, kernel_h,\n",
    "                                              self.padding,\n",
    "                                              out_pad_h)\n",
    "        out_width = conv_utils.deconv_length(width,\n",
    "                                             stride_w, kernel_w,\n",
    "                                             self.padding,\n",
    "                                             out_pad_w)\n",
    "        if self.data_format == 'channels_first':\n",
    "            output_shape = (batch_size, self.filters, out_height, out_width)\n",
    "        else:\n",
    "            output_shape = (batch_size, out_height, out_width, self.filters)\n",
    "            \n",
    "        #Spectral Normalization    \n",
    "        def _l2normalize(v, eps=1e-12):\n",
    "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
    "        def power_iteration(W, u):\n",
    "            #Accroding the paper, we only need to do power iteration one time.\n",
    "            _u = u\n",
    "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
    "            _u = _l2normalize(K.dot(_v, W))\n",
    "            return _u, _v\n",
    "        W_shape = self.kernel.shape.as_list()\n",
    "        #Flatten the Tensor\n",
    "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
    "        _u, _v = power_iteration(W_reshaped, self.u)\n",
    "        #Calculate Sigma\n",
    "        sigma=K.dot(_v, W_reshaped)\n",
    "        sigma=K.dot(sigma, K.transpose(_u))\n",
    "        #normalize it\n",
    "        W_bar = W_reshaped / sigma\n",
    "        #reshape weight tensor\n",
    "        if training in {0, False}:\n",
    "            W_bar = K.reshape(W_bar, W_shape)\n",
    "        else:\n",
    "            with tf.control_dependencies([self.u.assign(_u)]):\n",
    "                W_bar = K.reshape(W_bar, W_shape)\n",
    "        self.kernel = W_bar\n",
    "        \n",
    "        outputs = K.conv2d_transpose(\n",
    "            inputs,\n",
    "            self.kernel,\n",
    "            output_shape,\n",
    "            self.strides,\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNoise_std = 0.003\n",
    "\n",
    "def res_block_down(layer_input, filters):\n",
    "    d = BatchNormalization()(layer_input)\n",
    "    d = Activation('relu')(d)\n",
    "    d = ConvSN2D(filters, kernel_size=3, strides=2, padding='same')(d)\n",
    "    d = GaussianNoise(stddev=GaussianNoise_std)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Activation('relu')(d)\n",
    "    d = ConvSN2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "    d = GaussianNoise(stddev=GaussianNoise_std)(d)\n",
    "    d_res = ConvSN2D(filters, kernel_size=1, strides=2, padding='same')(layer_input)\n",
    "    d = Add()([d, d_res])\n",
    "    return d\n",
    "\n",
    "def res_block_up(layer_input, filters):\n",
    "    d = BatchNormalization()(layer_input)\n",
    "    d = Activation('relu')(d)\n",
    "    d = UpSampling2D(size=(2, 2), interpolation=\"nearest\")(d)\n",
    "    d = ConvSN2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "    d = GaussianNoise(stddev=GaussianNoise_std)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Activation('relu')(d)\n",
    "    d = ConvSN2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "    d = GaussianNoise(stddev=GaussianNoise_std)(d)\n",
    "    d_res = UpSampling2D(size=(2, 2), interpolation=\"nearest\")(layer_input)\n",
    "    d_res = ConvSN2D(filters, kernel_size=1, strides=1, padding='same')(d_res)\n",
    "    d = Add()([d, d_res])\n",
    "    return d\n",
    "\n",
    "# @tf.keras.utils.register_keras_serializable(package='Custom', name='Wvar_reg')\n",
    "def Wvar_reg(weight_matrix):\n",
    "    return tf.math.reduce_mean(tf.math.reduce_variance(weight_matrix))\n",
    "\n",
    "def BuildEncoder():\n",
    "    enc_input = Input(shape=img_shape, name='encoder_input') \n",
    "    X = ConvSN2D(64, kernel_size=3, padding='same', activation='relu')(enc_input)\n",
    "    X = res_block_down(X, 128)\n",
    "    X = res_block_down(X, 256)\n",
    "    X = res_block_down(X, 512)\n",
    "    X = res_block_down(X, 512)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = GaussianNoise(stddev=GaussianNoise_std)(X)\n",
    "    X = swish(X) #############\n",
    "        \n",
    "    z = DenseSN(latent_dim)(X)\n",
    "    z = GaussianNoise(stddev=GaussianNoise_std)(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    \n",
    "    z_split = Lambda( lambda x: tf.split(x,num_or_size_splits=latent_dim//5,axis=1))(z) \n",
    "    # clfscore = Dense(1, activation='sigmoid')(z_split[0])\n",
    "    clfscore = Dense(1, activation='sigmoid', kernel_regularizer=Wvar_reg)(z_split[0])\n",
    "    \n",
    "    encoder = Model(enc_input, [z, clfscore], name='encoder')\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "def BuildGenerator():\n",
    "    dec_input = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "    last_conv_shape = (4, 4, 512)\n",
    "    X = DenseSN(last_conv_shape[0] * last_conv_shape[1] * last_conv_shape[2])(dec_input)\n",
    "    X = GaussianNoise(stddev=GaussianNoise_std)(X)\n",
    "    X = Reshape((last_conv_shape[0], last_conv_shape[1], last_conv_shape[2]))(X)\n",
    "    \n",
    "    X = res_block_up(X, 512)\n",
    "    X = res_block_up(X, 512)\n",
    "    X = res_block_up(X, 256)\n",
    "    X = res_block_up(X, 128)\n",
    "    \n",
    "    X = ConvSN2D(1, (3, 3), strides = (1,1), padding = 'same', kernel_initializer = ker_init)(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "    decoder = Model(dec_input, X, name='decoder')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block_up(layer_input, filters):\n",
    "    d = BatchNormalization()(layer_input)\n",
    "    d = Activation('relu')(d)\n",
    "    d = UpSampling2D(size=(2, 2), interpolation=\"nearest\")(d)\n",
    "    d = ConvSN2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "    d = GaussianNoise(stddev=GaussianNoise_std)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Activation('relu')(d)\n",
    "    d = ConvSN2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "    d = GaussianNoise(stddev=GaussianNoise_std)(d)\n",
    "    d_res = UpSampling2D(size=(2, 2), interpolation=\"nearest\")(layer_input)\n",
    "    d_res = ConvSN2D(filters, kernel_size=1, strides=1, padding='same')(d_res)\n",
    "    d = Add()([d, d_res])\n",
    "    return d\n",
    "\n",
    "def BuildGenerator():\n",
    "    dec_input = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "    last_conv_shape = (4, 4, 512)\n",
    "    X = DenseSN(last_conv_shape[0] * last_conv_shape[1] * last_conv_shape[2])(dec_input)\n",
    "    X = GaussianNoise(stddev=GaussianNoise_std)(X)\n",
    "    X = Reshape((last_conv_shape[0], last_conv_shape[1], last_conv_shape[2]))(X)\n",
    "    \n",
    "    X = res_block_up(X, 512)\n",
    "    X = res_block_up(X, 512)\n",
    "    X = res_block_up(X, 256)\n",
    "    X = res_block_up(X, 128)\n",
    "    \n",
    "    X = ConvSN2D(1, (3, 3), strides = (1,1), padding = 'same', kernel_initializer = ker_init)(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "    decoder = Model(dec_input, X, name='decoder')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildDiscriminator1D():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2048, input_dim=latent_dim))\n",
    "    model.add(BatchNormalization(scale=False))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add((Dense(2048)))\n",
    "    model.add(BatchNormalization(scale=False))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add((Dense(2048)))\n",
    "    model.add(BatchNormalization(scale=False))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add((Dense(2048)))\n",
    "    model.add(BatchNormalization(scale=False))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add((Dense(2048)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add((Dense(2048)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    encoded_repr = Input(shape=(latent_dim, ))\n",
    "    validity = model(encoded_repr)\n",
    "    return Model(encoded_repr, validity, name='discriminator')\n",
    "\n",
    "def build_disentangleNET():\n",
    "    disentangleNET_input = Input(shape=img_shape, name='disentangleNET_input') # batchx128x128x1    \n",
    "    x = Conv2D(32, 5, strides=2, padding=\"same\", name=\"rec_conv1_preact\")(disentangleNET_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(64, 5, strides=2, padding=\"same\", name=\"rec_conv2_preact\")(x) \n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(128, 5, strides=2, padding=\"same\", name=\"rec_conv3_preact\")(x)  \n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(256, 5, strides=2, padding=\"same\", name=\"rec_conv4_preact\")(x)  \n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    disentangleNET_output = Dense(latent_dim, activation='softmax')(x)\n",
    "    disentangleNET_value = Dense(1)(x)\n",
    "    disentangleNET = Model(disentangleNET_input, [disentangleNET_output], name=\"disentangleNET\")\n",
    "    return disentangleNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray2rgb(tensor):\n",
    "    tensor = tf.image.grayscale_to_rgb(tensor)\n",
    "    return tensor\n",
    "\n",
    "def polynomial_kernel(features_1, features_2):\n",
    "        feature_dimensions = tf.cast(tf.shape(features_1)[1], dtype=tf.float32)\n",
    "        return (features_1 @ tf.transpose(features_2) / feature_dimensions + 1.0) ** 3.0\n",
    "\n",
    "def dist_sim_wrapper(model):\n",
    "    def dist_sim_loss(y_true, y_pred):\n",
    "        real_features = model( Lambda(gray2rgb)(y_true) ) \n",
    "        generated_features = model( Lambda(gray2rgb)(y_pred) )  \n",
    "        \n",
    "        loss = K.mean(real_features - generated_features) \n",
    "        \n",
    "        # kernel_real = polynomial_kernel(real_features, real_features)\n",
    "        # kernel_generated = polynomial_kernel( generated_features, generated_features)\n",
    "        # kernel_cross = polynomial_kernel(real_features, generated_features)\n",
    "        # batch_size = tf.shape(real_features)[0]\n",
    "        # batch_size_f = tf.cast(batch_size, dtype=tf.float32)\n",
    "        # mean_kernel_real = tf.reduce_sum(kernel_real * (1.0 - tf.eye(batch_size))) / (batch_size_f * (batch_size_f - 1.0))\n",
    "        # mean_kernel_generated = tf.reduce_sum(kernel_generated * (1.0 - tf.eye(batch_size))) / (batch_size_f * (batch_size_f - 1.0))\n",
    "        # mean_kernel_cross = tf.reduce_mean(kernel_cross)\n",
    "        # loss = mean_kernel_real + mean_kernel_generated - 2.0 * mean_kernel_cross\n",
    "        \n",
    "        return loss\n",
    "    return dist_sim_loss\n",
    "\n",
    "# def calc_cov_metric(z):\n",
    "#     cov = tfp.stats.covariance(z)\n",
    "#     diag_mean = tf.reduce_sum(tf.linalg.diag_part(cov)) / cov.shape[0]\n",
    "#     off_diag_mean = ( tf.reduce_sum(cov) - tf.reduce_sum(tf.linalg.diag_part(cov)) ) / (cov.shape[0]*2 - cov.shape[0])\n",
    "#     cov_loss = tf.reduce_mean((diag_mean - noise_var)**2) + tf.reduce_mean(off_diag_mean**2)\n",
    "#     return cov_loss, diag_mean, off_diag_mean\n",
    "\n",
    "def z_mean_var_loss(z):\n",
    "    loss = K.abs(K.var(z)-1) + K.abs(K.mean(z))\n",
    "    return K.mean(loss)\n",
    "\n",
    "def get_off_diag_values(x):\n",
    "    x_flat = tf.reshape(x,[-1])[:-1]\n",
    "    x_reshape = tf.reshape(x_flat,[x.shape[0]-1, x.shape[0]+1])[:, 1:]\n",
    "    off_diag_values = tf.reshape(x_reshape,[-1])\n",
    "    return off_diag_values\n",
    "def cov_loss_terms(z_batch):\n",
    "    z_batch = z_batch - tf.reduce_mean(z_batch, axis=0)\n",
    "    z_std = tf.sqrt(tf.math.reduce_variance(z_batch, axis=0) + 0.0001)\n",
    "    z_std_loss = tf.reduce_mean( tf.nn.relu(1 - z_std) )\n",
    "    cov = (tf.transpose(z_batch) @ z_batch) / (z_batch.shape[0] ) # cov = 1/N*(z.T*z)  tfp.stats.covariance(z_batch)\n",
    "    diag_cov = tf.linalg.diag_part(cov) # vector of vars (z_std**2)  positives\n",
    "    diag_cov_mean = tf.reduce_mean(tf.abs(diag_cov))    \n",
    "    off_diag_loss    = tf.reduce_mean(tf.abs( get_off_diag_values(cov) ))\n",
    "    off_diag_mean_10 = tf.reduce_mean(tf.abs(get_off_diag_values(cov[0:10,0:10])))\n",
    "    return cov, z_std_loss, diag_cov_mean , off_diag_loss, off_diag_mean_10 \n",
    "\n",
    "\n",
    "def calc_dimcor_loss(z, scores):\n",
    "    cor = []\n",
    "    N_dim = 5\n",
    "    for i in range(N_dim):\n",
    "        cor.append( tfp.stats.correlation(z[:,i] , scores[:,0], sample_axis=0, event_axis=None) )\n",
    "    first_cor_loss = 1 - tf.reduce_mean(tf.abs(cor)) # with or without abs?\n",
    "    \n",
    "    for i in range(N_dim+1, latent_dim):\n",
    "        cor.append( tfp.stats.correlation(z[:,i] , scores[:,0], sample_axis=0, event_axis=None) )\n",
    "    rest_cor_loss = tf.reduce_mean(tf.abs(cor)) # with or without abs?\n",
    "    \n",
    "    return first_cor_loss + rest_cor_loss\n",
    "\n",
    "\n",
    "def Wmae_loss(y_true, y_pred):\n",
    "    mae = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "    th = 0.05\n",
    "    booli = K.cast(K.greater(mae, th), 'float32') # keep bad samples (high loss)\n",
    "#     booli = K.cast(K.less_equal(mae, th), 'float32') # keep good samples (small loss)\n",
    "    wmae = booli * mae\n",
    "    wmae = K.sum(wmae) / K.sum(booli) \n",
    "    return wmae\n",
    "\n",
    "# def model_perc_loss_wrapper(model):\n",
    "#     def model_perc_loss(y_true, y_pred):\n",
    "#         # weights = [1,1,1]\n",
    "#         img_outputs = model( y_true ) \n",
    "#         recon_img_outputs = model( y_pred ) \n",
    "#         layers_losses = []\n",
    "#         for i in range(len(recon_img_outputs)):\n",
    "#             mae_losses = K.abs(img_outputs[i] - recon_img_outputs[i])\n",
    "#             layers_losses.append(K.mean(mae_losses))\n",
    "#         avg_loss = K.mean(tf.convert_to_tensor(layers_losses))\n",
    "#         return avg_loss\n",
    "#     return model_perc_loss\n",
    "\n",
    "def perc_loss(model, y_true, y_pred):\n",
    "    # weights = [1,1,1]\n",
    "    y_true = Lambda(gray2rgb)(y_true)\n",
    "    y_pred = Lambda(gray2rgb)(y_pred)\n",
    "    img_outputs = model( y_true ) \n",
    "    recon_img_outputs = model( y_pred ) \n",
    "    layers_losses = []\n",
    "    for i in range(len(recon_img_outputs)):\n",
    "        mae_losses = K.abs(img_outputs[i] - recon_img_outputs[i])\n",
    "        layers_losses.append(K.mean(mae_losses))\n",
    "    avg_loss = K.mean(tf.convert_to_tensor(layers_losses))\n",
    "    return avg_loss\n",
    "\n",
    "def perturbate_embedding(z_image_batch):\n",
    "    GT_onehot_vecs = np.zeros((z_image_batch.shape[0], latent_dim)) # vectors of zeros which will get 1 in a random dim\n",
    "    pert_onehot_vecs = np.copy(GT_onehot_vecs) # vectors of zeros which will get a value in a random dim , it is added to z in the graph\n",
    "    for i in range(z_image_batch.shape[0]):\n",
    "        pert_dim = np.random.randint(latent_dim, size=1)[0] # choose a dim\n",
    "        values = np.linspace(-6, 6, num=100)\n",
    "        values[np.where( (values<-1) | (values>1) )]\n",
    "        pert_value = tf.random.shuffle(values)[0] # choose a value from values\n",
    "        pert_onehot_vecs[i][pert_dim] = pert_value # change z to selected value\n",
    "        GT_onehot_vecs[i][pert_dim] = 1 # put value 1 in one hot\n",
    "    pert_onehot_vecs = np.array(pert_onehot_vecs)\n",
    "    GT_onehot_vecs = np.array(GT_onehot_vecs)\n",
    "    return pert_onehot_vecs, GT_onehot_vecs\n",
    "\n",
    "def polynomial_kernel(features_1, features_2):\n",
    "        feature_dimensions = tf.cast(tf.shape(features_1)[1], dtype=tf.float32)\n",
    "        return (features_1 @ tf.transpose(features_2) / feature_dimensions + 1.0) ** 3.0\n",
    "def z_mmd_loss2(real_features, generated_features):\n",
    "    kernel_real = polynomial_kernel(real_features, real_features)\n",
    "    kernel_generated = polynomial_kernel( generated_features, generated_features)\n",
    "    kernel_cross = polynomial_kernel(real_features, generated_features)\n",
    "    batch_size = tf.shape(real_features)[0]\n",
    "    batch_size_f = tf.cast(batch_size, dtype=tf.float32)\n",
    "    mean_kernel_real = tf.reduce_sum(kernel_real * (1.0 - tf.eye(batch_size))) / (batch_size_f * (batch_size_f - 1.0))\n",
    "    mean_kernel_generated = tf.reduce_sum(kernel_generated * (1.0 - tf.eye(batch_size))) / (batch_size_f * (batch_size_f - 1.0))\n",
    "    mean_kernel_cross = tf.reduce_mean(kernel_cross)\n",
    "    kid = mean_kernel_real + mean_kernel_generated - 2.0 * mean_kernel_cross\n",
    "    return kid\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.001)\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "\n",
    "def multi_layer_second_directional_derivative(G, z, x, epsilon):\n",
    "    G_z = [G(z)]\n",
    "    G_to_x = [G(z + x)]\n",
    "    G_from_x = [G(z - x)]\n",
    "    sdd = [(G2x - 2 * G_z_base + Gfx) / epsilon**2 for G2x, G_z_base, Gfx in zip(G_to_x, G_z, G_from_x)] # len=1 , sdd[0] 64,64,64,1\n",
    "    return sdd\n",
    "def hessian_penalty(G, z, k):\n",
    "    epsilon=0.1\n",
    "    second_orders = []\n",
    "    for _ in range(k): \n",
    "        rademacher_tensors = tfp.random.rademacher(tf.shape(z)) # (bs, zdim)\n",
    "        x = epsilon * rademacher_tensors # (bs, zdim)\n",
    "        central_second_order = multi_layer_second_directional_derivative(G, z, x, epsilon)   ########## # len=1 , sdd[0] 64,64,64,1\n",
    "        second_orders.append(central_second_order) # (k,1,  64,64,64,1)\n",
    "    \n",
    "    sum_of_penalties = 0 \n",
    "    for activ_n in zip(*second_orders): \n",
    "        second_orders__ = tf.stack(activ_n) # (100, 64, 64, 64, 1)\n",
    "        _, var_tensor = tf.nn.moments(second_orders__, axes=(0,)) # var_tensor (64, 64, 64, 1)\n",
    "        penalty = tf.reduce_max(var_tensor)  # (1,) (scalar) \n",
    "        sum_of_penalties += penalty \n",
    "    return sum_of_penalties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CNN_saved_name = 'classifier.h5' # new\n",
    "CNN_clf_model_path = data_path + 'GENDER/GENDER_SAVED_MODELS/' + CNN_saved_name\n",
    "CNN_clf_model = load_model(CNN_clf_model_path , compile=True)\n",
    "CNN_clf_model.trainable = False # we dont train the CNN\n",
    "\n",
    "clf_outputs = [\n",
    "               CNN_clf_model.get_layer('block2_conv1').output,\n",
    "               CNN_clf_model.get_layer('block2_conv2').output,\n",
    "               CNN_clf_model.get_layer('block3_conv2').output,\n",
    "               CNN_clf_model.get_layer('block3_conv3').output,\n",
    "               CNN_clf_model.get_layer('block5_conv2').output,\n",
    "               CNN_clf_model.get_layer('block5_conv3').output,\n",
    "               CNN_clf_model.get_layer('flatten').output,\n",
    "               CNN_clf_model.get_layer('dense_1').output,]\n",
    "                  \n",
    "CNN_clf_Model_outputs = Model(inputs=CNN_clf_model.input, outputs = clf_outputs)\n",
    "CNN_clf_Model_outputs.trainable = False # we dont train the CNN\n",
    "\n",
    "VGG_model = VGG19(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size,3)) # ResNet50 , VGG16, VGG19\n",
    "VGG_outputs = [\n",
    "               # VGG_model.get_layer('block1_conv1').output,   \n",
    "               # VGG_model.get_layer('block1_conv2').output,\n",
    "               # VGG_model.get_layer('block2_conv1').output,\n",
    "               # VGG_model.get_layer('block2_conv2').output,   \n",
    "               VGG_model.get_layer('block3_conv1').output,   \n",
    "               VGG_model.get_layer('block3_conv2').output,\n",
    "               VGG_model.get_layer('block3_conv3').output,\n",
    "               VGG_model.get_layer('block4_conv1').output,\n",
    "               VGG_model.get_layer('block4_conv2').output,\n",
    "               VGG_model.get_layer('block4_conv3').output,\n",
    "               VGG_model.get_layer('block4_conv4').output,\n",
    "               VGG_model.get_layer('block5_conv1').output,\n",
    "               VGG_model.get_layer('block5_conv2').output,\n",
    "               VGG_model.get_layer('block5_conv3').output,\n",
    "               VGG_model.get_layer('block5_conv4').output,]\n",
    "VGG_Model_outputs = Model(inputs=VGG_model.input, outputs = VGG_outputs)\n",
    "VGG_Model_outputs.trainable = False # we dont train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = BuildEncoder()\n",
    "generator = BuildGenerator()\n",
    "disentangleNET = build_disentangleNET()\n",
    "discriminator1D = BuildDiscriminator1D()\n",
    "# discriminatorDW = BuildDiscriminatorDW()\n",
    "\n",
    "# load weights to model\n",
    "if upload_saved_model == 1:\n",
    "    model_path = data_path + 'GENDER/GENDER_SAVED_MODELS/'\n",
    "    encoder.load_weights(model_path + 'encoder' + '.h5')\n",
    "    generator.load_weights(model_path + 'generator' + '.h5')\n",
    "    disentangleNET.load_weights(model_path + 'disentangleNET' + '.h5')\n",
    "    discriminator1D.load_weights(model_path + 'discriminator1D' + '.h5')\n",
    "\n",
    "ae_optimizer=Adam(LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2)\n",
    "disc1D_optimizer=Adam(LEARNING_RATE/10, beta_1=BETA_1, beta_2=BETA_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_batch_size = 200\n",
    "test_images = X_test[np.random.randint(0, X_test.shape[0], test_batch_size)] / 255 \n",
    "test_images_scores = CNN_clf_model( test_images.repeat(3, -1) )\n",
    "test_noise = np.random.normal(0,noise_var, size=(test_batch_size, latent_dim))\n",
    "test_real_y = 0.9*np.ones((test_batch_size, 1))\n",
    "test_fake_y = 0.1*np.ones((test_batch_size, 1))\n",
    "\n",
    "real_y = 0.9*np.ones((BATCHSIZE, 1))\n",
    "fake_y = 0.1*np.ones((BATCHSIZE, 1))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"epoch\", epoch)\n",
    "    iteration = 0\n",
    "    for n_batch in range(len(X_train) // BATCHSIZE): \n",
    "        # training function start\n",
    "        # train encoder \n",
    "        for i in range(1):\n",
    "            idx = np.random.randint(0, X_train.shape[0], 2*BATCHSIZE)\n",
    "            image_batch = np.copy(X_train[idx]) / 255\n",
    "            if do_augmentations == 1:\n",
    "                image_batch = augment_imgs(image_batch)\n",
    "                \n",
    "            ## choose high perc loss images\n",
    "            recon_image_batch = generator.predict(encoder.predict(image_batch)[0]) \n",
    "            samples_perc_loss = []\n",
    "            for i in range(2*BATCHSIZE):\n",
    "                samples_perc_loss.append( perc_loss(VGG_Model_outputs, image_batch[i:i+1], recon_image_batch[i:i+1]) )\n",
    "            samples_perc_loss = np.array(samples_perc_loss)\n",
    "            sorted_ind = np.argsort(samples_perc_loss)[::-1]\n",
    "            # sorted_samples_perc_loss = samples_perc_loss[sorted_ind]\n",
    "            # sorted_samples_perc_loss = sorted_samples_perc_loss[~np.isnan(sorted_samples_perc_loss)] # remove nan\n",
    "            sorted_images = image_batch[sorted_ind]\n",
    "            image_batch = sorted_images[0:BATCHSIZE]\n",
    "                \n",
    "            imgs_clfscore = CNN_clf_model(image_batch.repeat(3, -1))\n",
    "            with tf.GradientTape() as tape:\n",
    "                z_imgs, z_scores = encoder(image_batch, training=True)\n",
    "                recon_imgs = generator(z_imgs, training=True)\n",
    "                ## disentangler part\n",
    "                pert_z_vecs, GT_onehot_vecs = perturbate_embedding(z_imgs)\n",
    "                pert_imgs = generator(z_imgs + pert_z_vecs, training=True) ## only predict\n",
    "                pert_diff = tf.abs(pert_imgs - recon_imgs) ### abs or not\n",
    "                onehot_dim_pred = disentangleNET(pert_diff, training=True) \n",
    "                pert__pert_imgs = generator(encoder(pert_imgs, training=True)[0] - pert_z_vecs, training=True )\n",
    "                \n",
    "                ## disciriminator1D adv\n",
    "                z_discriminator1D_out = discriminator1D(z_imgs, training=True) # adversarial \n",
    "                # z_discriminatorDW_out = discriminatorDW(tf.transpose(z_imgs), training=True) # adversarial \n",
    "                ## loss\n",
    "                CLF_perc_loss = perc_loss(CNN_clf_Model_outputs, image_batch, recon_imgs)\n",
    "                VGG_perc_loss = perc_loss(VGG_Model_outputs, image_batch, recon_imgs)\n",
    "                # MAE_loss = K.mean(K.abs(image_batch - recon_imgs))\n",
    "                z_score_loss = bce(imgs_clfscore, z_scores) + bce(z_scores , imgs_clfscore) # bce(imgs_clfscore, z_scores) # calc_dimcor_loss(z_imgs, imgs_clfscore)\n",
    "                # z_score_loss_cor = calc_dimcor_loss(z_imgs, imgs_clfscore)\n",
    "                disent_loss = cce(GT_onehot_vecs , onehot_dim_pred)\n",
    "                # pert_diff_loss = tf.reduce_mean(pert_diff) - tf.math.reduce_variance(pert_diff)\n",
    "                # pert_consistency_loss = perc_loss(CNN_clf_Model_outputs, pert_imgs, pert__pert_imgs)\n",
    "                # pert_CLF_perc_loss = perc_loss(CNN_clf_Model_outputs, image_batch, pert_imgs)\n",
    "                # pert_VGG_perc_loss = perc_loss(VGG_Model_outputs, image_batch, pert_imgs)\n",
    "                z_discriminator1D_loss = tf.cast(bce(real_y, z_discriminator1D_out), tf.float32)\n",
    "                # z_discriminatorDW_loss = tf.cast(bce( 0.9*np.ones((latent_dim, 1)) , z_discriminatorDW_out), tf.float32)\n",
    "                z_mean_var_loss_ = z_mean_var_loss(z_imgs)\n",
    "                cov, z_std_loss, diag_cov_mean , off_diag_loss, off_diag_mean_10 = cov_loss_terms(z_imgs)\n",
    "                cov_loss = 0.5*diag_cov_mean + 0.5*z_std_loss\n",
    "                # H_loss = hessian_penalty(generator, z_imgs[0:8], k=10)\n",
    "                # pert_recon_loss = K.mean(K.abs(recon_imgs - generator(z_imgs + 0.3*tf.random.normal(shape=(BATCHSIZE, latent_dim)), training=True) ))\n",
    "                \n",
    "                ############ total loss ################\n",
    "                \n",
    "                recon_loss = 5*CLF_perc_loss + 5*VGG_perc_loss\n",
    "                latent_space_loss = 1*z_score_loss + 1*z_discriminator1D_loss + 1*cov_loss + 1*z_mean_var_loss_ # + 1*z_discriminatorDW_loss\n",
    "                perturbation_loss = 1*disent_loss\n",
    "                ae_loss = recon_loss + latent_space_loss + perturbation_loss\n",
    "       \n",
    "                \n",
    "            ## ae BP (discriminator isnt trainable)\n",
    "            trainable_variables = encoder.trainable_variables + generator.trainable_variables + disentangleNET.trainable_variables \n",
    "            ae_gradients = tape.gradient(ae_loss, trainable_variables)\n",
    "            ae_optimizer.apply_gradients(zip(ae_gradients, trainable_variables))\n",
    "            \n",
    "            ## discriminator1D/DW\n",
    "            idx = np.random.randint(0, X_train.shape[0], BATCHSIZE)\n",
    "            image_batch = np.copy(X_train[idx]) / 255\n",
    "            if do_augmentations == 1:\n",
    "                image_batch = augment_imgs(image_batch)\n",
    "            rand_vecs = tf.random.normal(shape=(BATCHSIZE, latent_dim))\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                z_imgs, z_scores = encoder(image_batch, training=True)\n",
    "                z_discriminator1D_out = discriminator1D(z_imgs, training=True)\n",
    "                r_discriminator1D_out = discriminator1D(rand_vecs, training=True)\n",
    "                # z_discriminatorDW_out = discriminatorDW(tf.transpose(z_imgs), training=True)\n",
    "                # r_discriminatorDW_out = discriminatorDW(tf.transpose(rand_vecs), training=True)\n",
    "                # loss\n",
    "                discriminator1D_loss = 0.5*bce(real_y, r_discriminator1D_out) + 0.5*bce(fake_y, z_discriminator1D_out)\n",
    "                discriminator1D_loss = tf.cast(discriminator1D_loss, tf.float32)\n",
    "                # discriminatorDW_loss = 0.5*bce( 0.9*np.ones((latent_dim, 1)) , r_discriminatorDW_out) + 0.5*bce( 0.1*np.ones((latent_dim, 1)) , z_discriminatorDW_out)\n",
    "                # discriminatorDW_loss = tf.cast(discriminatorDW_loss, tf.float32)\n",
    "            ## BP disc1D \n",
    "            trainable_variables = discriminator1D.trainable_variables\n",
    "            disc1D_gradients = tape.gradient(discriminator1D_loss, trainable_variables)\n",
    "            disc1D_optimizer.apply_gradients(zip(disc1D_gradients, trainable_variables))\n",
    "            ## BP discDW \n",
    "            # trainable_variables = discriminatorDW.trainable_variables\n",
    "            # discDW_gradients = tape.gradient(discriminatorDW_loss, trainable_variables)\n",
    "            # discDW_optimizer.apply_gradients(zip(discDW_gradients, trainable_variables))\n",
    "            \n",
    "# TEST ###########################################\n",
    "        iteration = iteration + 1\n",
    "        if iteration % 1 == 0: \n",
    "            print('iteration ' , iteration)\n",
    "            test_z_images, test_z_scores  = encoder.predict(test_images)\n",
    "            test_recon_images = generator.predict(test_z_images)\n",
    "            test_generated_images = generator.predict(test_noise)\n",
    "            test_recon_images_scores = CNN_clf_model(test_recon_images.repeat(3, -1))\n",
    "\n",
    "            # disent\n",
    "            test_pert_z_vecs, test_GT_onehot_vecs = perturbate_embedding(test_z_images)\n",
    "            test_pert_imgs = generator.predict(test_z_images + test_pert_z_vecs)\n",
    "            test_pert_diff = tf.abs(test_pert_imgs - test_recon_images)\n",
    "            test_onehot_dim_pred = disentangleNET.predict(test_pert_diff) ### abs or not\n",
    "            test_dim_pred = np.argmax(test_onehot_dim_pred, axis=1)\n",
    "            test_disentangleNET_acc = len(test_dim_pred[test_dim_pred==np.argmax(test_GT_onehot_vecs, axis=1)]) / len(test_dim_pred)\n",
    "            test_pert_CLF_perc_loss = perc_loss(CNN_clf_Model_outputs, test_images, test_pert_imgs).numpy()\n",
    "            test_pert_VGG_perc_loss = perc_loss(VGG_Model_outputs, test_images, test_pert_imgs).numpy()\n",
    "            test_pert__pert_imgs = generator.predict(encoder.predict(test_pert_imgs)[0] - test_pert_z_vecs )\n",
    "            \n",
    "            # test losses\n",
    "            test_CLF_loss = np.round(perc_loss(CNN_clf_Model_outputs, test_images, test_recon_images).numpy(),3)\n",
    "            test_VGG_loss = np.round(perc_loss(VGG_Model_outputs, test_images, test_recon_images).numpy(),3)\n",
    "            test_z_scores_loss = np.round(K.mean(K.abs(test_images_scores - test_z_scores)).numpy(),3)\n",
    "            test_disent_acc = np.round(test_disentangleNET_acc,3)\n",
    "            test_cov, test_z_std_loss, test_diag_cov_mean , test_off_diag_loss, test_off_diag_mean_10 = cov_loss_terms(test_z_images)\n",
    "            test_pert_consistency_loss = perc_loss(CNN_clf_Model_outputs, test_pert_imgs, test_pert__pert_imgs)\n",
    "            test_pert_diff_loss = tf.reduce_mean(test_pert_diff)\n",
    "            \n",
    "            print(  '                 train   ' ,   '  test')\n",
    "            print('CLF_loss    ' , CLF_perc_loss.numpy() , '   ',  test_CLF_loss)\n",
    "            print('VGG_loss    ' , VGG_perc_loss.numpy() , '   ',  test_VGG_loss)\n",
    "\n",
    "            # print('perc_CLF_loss    ' , pert_CLF_perc_loss.numpy() , '   ',  test_pert_CLF_perc_loss)\n",
    "            # print('perc_VGG_loss    ' , pert_VGG_perc_loss.numpy() , '   ',  test_pert_VGG_perc_loss)\n",
    "            # print('pert_consistency_loss  ' , pert_consistency_loss.numpy(), '   ', test_pert_consistency_loss.numpy())\n",
    "            print('pert_diffsize_loss  ' , pert_diff_loss.numpy(), '   ', test_pert_diff_loss.numpy())\n",
    "            print('z_scores_mae_loss    ' , z_score_loss.numpy(), '   ', test_z_scores_loss)\n",
    "            print('disent_loss' , cce(test_GT_onehot_vecs , test_onehot_dim_pred).numpy() , test_disent_acc )\n",
    "            print('disc1D rand' , bce(test_real_y, discriminator1D(test_noise, training=True)).numpy() )\n",
    "            print('disc1D z' , bce(test_fake_y, discriminator1D(test_z_images, training=True)).numpy() )\n",
    "            print( 'mean_diag' , tf.reduce_mean(tf.linalg.diag_part(test_cov)).numpy(), 'off_diag_loss', test_off_diag_loss.numpy(), 'test_off_diag_mean_10', test_off_diag_mean_10.numpy()  )\n",
    "            \n",
    "            print('')\n",
    "            print('MAE_loss' ,  K.mean(K.abs(image_batch - recon_imgs)).numpy(),' ', K.mean(K.abs(test_images - test_recon_images)).numpy())\n",
    "            print('Other metrics')\n",
    "            print( '[z_var, z_mean]' , np.var(test_z_images) , np.mean(test_z_images) )\n",
    "            print('recon_scores_mae_loss' , np.mean(np.abs(CNN_clf_model(test_recon_images.repeat(3, -1)) - test_images_scores)) ) \n",
    "            print( 'weights: ' , np.sort(np.abs(encoder.layers[-1].get_weights()[0].flatten())) )\n",
    "            \n",
    "            print('')\n",
    "            print('real')\n",
    "            sample_images(test_images)\n",
    "            print('')\n",
    "            print('recon')\n",
    "            sample_images(test_recon_images)\n",
    "            print('')\n",
    "\n",
    "            print('gen')\n",
    "            sample_images(test_generated_images)\n",
    "\n",
    "            _ = plt.hist(discriminator1D(test_noise, training=True).numpy().flatten(), 100, range=[0, 1], alpha = 0.5, color= 'b')\n",
    "            _ = plt.hist(discriminator1D(test_z_images, training=True).numpy().flatten(), 100, range=[0, 1], alpha = 0.5, color= 'r')\n",
    "            handles = [Rectangle((0,0),1,1,color=c,ec=\"k\") for c in [\"red\", \"blue\"] ]\n",
    "            labels= [\"z\", \"rand\"]\n",
    "            plt.legend(handles, labels)\n",
    "            plt.show()\n",
    "            \n",
    "            cor_vals = []\n",
    "            for i in range(latent_dim):\n",
    "                cor_vals.append( np.corrcoef(test_images_scores[:,0] , test_z_images[:,i])[0][1] )\n",
    "            cor_vals = np.array(cor_vals)\n",
    "            plt.figure(figsize=(30,10))\n",
    "            plt.bar(np.arange(latent_dim), cor_vals , width=1)\n",
    "#             df = pd.concat([pd.DataFrame(test_z_images) , pd.DataFrame(test_images_scores)] , axis=1).reset_index()\n",
    "#             df = df.drop( ['index'] , axis=1)\n",
    "#             cor = df.corr()\n",
    "#             \n",
    "#             plt.bar(np.array(df.columns[:-1]), cor.iloc[-1].values[:-1] , width=1) # normalized\n",
    "#             plt.xlabel(\"latent dimension\", fontsize=50)\n",
    "            plt.ylabel(\"correlation \", fontsize=50)\n",
    "            plt.xticks(fontsize=30)\n",
    "            plt.yticks(fontsize=30)\n",
    "            plt.ylim([-1,1])\n",
    "            plt.show()\n",
    "            \n",
    "            print(cor_vals[15:].max())\n",
    "            \n",
    "    if (epoch+1) % 1 == 0:\n",
    "        save_path = data_path + 'GENDER/GENDER_SAVED_MODELS/' \n",
    "        encoder.save(save_path + 'encoder.h5', include_optimizer=False)\n",
    "        generator.save(save_path + 'generator.h5', include_optimizer=False)\n",
    "        disentangleNET.save(save_path + 'disentangleNET.h5', include_optimizer=False)\n",
    "        discriminator1D.save(save_path + 'discriminator1D.h5', include_optimizer=False)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odedenv2",
   "language": "python",
   "name": "odedenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
